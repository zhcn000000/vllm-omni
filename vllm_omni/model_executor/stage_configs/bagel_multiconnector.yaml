# Stage 0: Thinker (multimodal understanding + text generation)

stage_args:
  - stage_id: 0
    stage_type: llm
    runtime:
      devices: "0"
      max_batch_size: 1
    engine_args:
      model_stage: thinker
      model_arch: BagelForConditionalGeneration
      worker_type: ar
      scheduler_cls: vllm_omni.core.sched.omni_ar_scheduler.OmniARScheduler
      gpu_memory_utilization: 0.35
      enforce_eager: true
      trust_remote_code: true
      engine_output_type: text
      distributed_executor_backend: "mp"
      enable_prefix_caching: false
      max_num_batched_tokens: 32768
      tensor_parallel_size: 1
      omni_kv_config:
        need_send_cache: true
        kv_transfer_criteria:
          type: prefill_finished #or special token generated
    final_output: true
    final_output_type: text
    is_comprehension: true
    default_sampling_params:
      temperature: 0.4
      top_p: 0.9
      top_k: 1
      max_tokens: 2048
      seed: 52
      detokenize: True
      repetition_penalty: 1.05
    output_connectors:
      to_stage_1: mooncake_connector


  - stage_id: 1
    stage_type: diffusion
    runtime:
      devices: "0"
      max_batch_size: 1
    engine_args:
      model_stage: dit
      gpu_memory_utilization: 0.55
      enforce_eager: true
      trust_remote_code: true
      engine_output_type: image
      distributed_executor_backend: "mp"
      enable_prefix_caching: false
      max_num_batched_tokens: 32768
      tensor_parallel_size: 1
      omni_kv_config:
        need_recv_cache: true
    engine_input_source: [0]

    final_output: true
    final_output_type: image
    is_comprehension: false
    default_sampling_params:
      seed: 52
    input_connectors:
      from_stage_0: mooncake_connector


# Runtime edges
runtime:
  enabled: true
  defaults:
    window_size: -1
    max_inflight: 1

  # Distributed connectors configuration (optional)
  # More connectors will be supported in the future.
  connectors:
    # Mooncake connector for cross-node/intra-node communication
    mooncake_connector:
      name: MooncakeStoreConnector
      extra:
        host: "127.0.0.1"
        metadata_server: "http://10.90.67.86:8080/metadata"
        master: "10.90.67.86:50051"
        segment: 512000000    # 512MB
        localbuf: 64000000     # 64MB
        proto: "tcp"

    # PR1 (#1019) note:
    # - Keep this transfer-engine connector config as a ready-to-use template.
    # - Bagel does NOT consume this connector in PR1(#1019).
    # - output_connectors/input_connectors above still point to mooncake_connector.
    # - We will switch Bagel to this connector in the next PR.
    rdma_connector:
      name: MooncakeTransferEngineConnector
      extra:
        # NOTE:
        # - role/sender_host/sender_zmq_port are internal fields resolved by
        #   orchestration logic and should not be set in user YAML.
        host: "auto"                  # Auto-detect local IP for RDMA
        zmq_port: 50051               # ZMQ base port (actual port uses runtime offsets)
        protocol: "rdma"
        device_name: ""               # e.g. "mlx5_0"; empty for auto-detect
        memory_pool_size: 2147483648  # 2GB
        memory_pool_device: "cpu"     # "cuda" for GPUDirect RDMA, "cpu" for pinned memory


  edges:
    - from: 0
      to: 1
      window_size: -1
